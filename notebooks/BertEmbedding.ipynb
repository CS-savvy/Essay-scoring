{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76cac4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88f90dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec36ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e586b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.tokenize(marked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87a86650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print (tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "178263d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2182, 2003, 1996, 6251, 1045, 2215, 7861, 8270, 4667, 2015, 2005, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.encode_plus(text, add_special_tokens=True)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24b295d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(tokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e2b05f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "886915b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_text_preparation(text, tokenizer):\n",
    "    \"\"\"Preparing the input for BERT\n",
    "    \n",
    "    Takes a string argument and performs\n",
    "    pre-processing like adding special tokens,\n",
    "    tokenization, tokens to ids, and tokens to\n",
    "    segment ids. All tokens are mapped to seg-\n",
    "    ment id = 1.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to be converted\n",
    "        tokenizer (obj): Tokenizer object\n",
    "            to convert text into BERT-re-\n",
    "            adable tokens and ids\n",
    "        \n",
    "    Returns:\n",
    "        list: List of BERT-readable tokens\n",
    "        obj: Torch tensor with token ids\n",
    "        obj: Torch tensor segment ids\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    return tokenized_text, tokens_tensor, segments_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cefc581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
    "    \"\"\"Get embeddings from an embedding model\n",
    "    \n",
    "    Args:\n",
    "        tokens_tensor (obj): Torch tensor size [n_tokens]\n",
    "            with token ids for each token in text\n",
    "        segments_tensors (obj): Torch tensor size [n_tokens]\n",
    "            with segment ids for each token in text\n",
    "        model (obj): Embedding model to generate embeddings\n",
    "            from token and segment ids\n",
    "    \n",
    "    Returns:\n",
    "        list: List of list of floats of size\n",
    "            [n_tokens, n_embedding_dimensions]\n",
    "            containing embeddings for each token\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Gradient calculation id disabled\n",
    "    # Model is in inference mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        # Removing the first hidden state\n",
    "        # The first state is the input state\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    # Getting embeddings from the final BERT layer\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    # Collapsing the tensor into 1-dimension\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "    # Converting torchtensors to lists\n",
    "    list_token_embeddings = [token_embed.tolist() for token_embed in token_embeddings]\n",
    "\n",
    "    return list_token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e20d007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"Ram and Shayam are playing.\"]\n",
    "         \n",
    "         # \"The bank vault was robust.\",\n",
    "         # \"He had to bank on her for support.\",\n",
    "         # \"The bank was out of money.\",\n",
    "         # \"The bank teller was a man.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58e34d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word_embeddings = []\n",
    "for text in texts:\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n",
    "    \n",
    "    # Find the position 'bank' in list of tokens\n",
    "    # word_index = tokenized_text.index('bank')\n",
    "    # Get the embedding for bank\n",
    "    # word_embedding = list_token_embeddings[word_index]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c400d4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, ['[CLS]', 'ram', 'and', 'shay', '##am', 'are', 'playing', '.', '[SEP]'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_token_embeddings), tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f662c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_token_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d157797d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18178808689117432,\n",
       " -0.42435935139656067,\n",
       " -0.33612990379333496,\n",
       " -0.9720714688301086,\n",
       " 0.7758705615997314,\n",
       " -0.2639223039150238,\n",
       " 0.8645139932632446,\n",
       " 0.1322741061449051,\n",
       " 0.08310992270708084,\n",
       " 0.45797717571258545]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_token_embeddings[1][:10] #ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0290d878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0274667739868164,\n",
       " -0.047883614897727966,\n",
       " 0.17032091319561005,\n",
       " -1.0732817649841309,\n",
       " -0.06276001036167145,\n",
       " -1.7902220487594604,\n",
       " 1.1028976440429688,\n",
       " 0.08875294774770737,\n",
       " 0.4522388279438019,\n",
       " 0.44802847504615784]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_token_embeddings[3][:10] #shay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcda0cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.06891278177499771,\n",
       " -0.8458523750305176,\n",
       " -0.5103632807731628,\n",
       " -1.2111579179763794,\n",
       " 1.299895167350769,\n",
       " -0.9131978750228882,\n",
       " 0.5076037049293518,\n",
       " 0.4665069580078125,\n",
       " 0.11558946967124939,\n",
       " 0.5410099029541016]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_token_embeddings[4][:10] #shay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af16f349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165456b4-035f-4cfb-ac21-a79e2776af3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
